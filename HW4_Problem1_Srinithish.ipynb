{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_Problem1_Srinithish.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinithish/Deep-Learning/blob/master/HW4_Problem1_Srinithish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBMKAHLckmUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import random\n",
        "import matplotlib.cm as cm\n",
        "import math\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import pickle as p\n",
        "import  itertools as itr\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BifQk5hYAU0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "Change directory path here and leave it blank if its in the same directory as the \n",
        "Notebook\n",
        "\"\"\"\n",
        "dirpath  = \"Drive/My Drive/Deeplearning Assignment/timit-homework\"\n",
        "dirpath  = \"\"\n",
        "\n",
        "\n",
        "with open(dirpath+'hw4_trs.pkl', 'rb') as f:\n",
        "  trainUtterances = p.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pbPELohqgHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###load files\n",
        "# !pip install librosa # in colab, you'll need to install this\n",
        "import librosa\n",
        "import io\n",
        "\n",
        "\n",
        "\n",
        "### Loading the files\n",
        "\n",
        "def gen_STFTnMagnitude(RawAmpVsTime):\n",
        "  \"\"\"\n",
        "  returns \n",
        "  time domain \n",
        "  complex spectrogram \n",
        "  magnitude spectrgoram\n",
        "  \"\"\"\n",
        "  \n",
        "  spectrogram = librosa.stft(RawAmpVsTime, n_fft=1024, hop_length=512)\n",
        "  spectrogram = np.transpose(spectrogram)\n",
        "  spectrogram_Mag = np.abs(spectrogram)\n",
        "  \n",
        "  return spectrogram,spectrogram_Mag\n",
        "\n",
        "def getSTFTs(AllRawAmpVsTime):\n",
        "  AllSTFTs = []\n",
        "  \n",
        "  for i in AllRawAmpVsTime:\n",
        "    spectrogram,spectrogram_Mag = gen_STFTnMagnitude(i)\n",
        "    AllSTFTs.append(spectrogram_Mag)\n",
        "\n",
        "  return AllSTFTs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GCdO6n_VKkr",
        "colab_type": "text"
      },
      "source": [
        "## Sampling functions for generating pairs\n",
        "\n",
        "1. For Train, Generating all possible 45 Positive pairs and 45 negative pairs for each 50 speakers\n",
        "  Hence will have array of dimensions (50,90,32,513)  here 32 * 513 is the stft'd array dimensions\n",
        "\n",
        "2. For Test, Generating all possible 45 Positive pairs and 45 negative pairs for each 10 speakers\n",
        "Hence will have array of dimensions (20,90,32,513)  here 45 * 513 is the stft'd array dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwPevMeFAL1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def positiveSampling(ConsideredSpeakerIndices,sampleNum = 5 ):\n",
        "  allPosPairs = list(itr.combinations(ConsideredSpeakerIndices,2))\n",
        "  if sampleNum is not None:\n",
        "     allPosPairs =  random.sample(allPosPairs,sampleNum)\n",
        "   \n",
        "  \n",
        "  return allPosPairs\n",
        "\n",
        "def negativeSampling(ConsideredSpeakerIndices,RestSpeakerIndices, sampleNum = 5):\n",
        "    allNegativePairs = list(itr.product(ConsideredSpeakerIndices,RestSpeakerIndices))\n",
        "    if sampleNum is not None:\n",
        "      allNegativePairs =  random.sample(allNegativePairs,sampleNum)\n",
        "    \n",
        "    return allNegativePairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqWTYf4_wkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def genAllSpeaker(numSpeakers, AllStftArray ):\n",
        "  AllStftArray = np.array(AllStftArray)\n",
        "  numTotalUtterances,lenClip , xDim = AllStftArray.shape\n",
        "  \n",
        "  utterancesPerSpeaker = int(numTotalUtterances//numSpeakers)\n",
        "  \n",
        "  AllIndices = list(range(numTotalUtterances))\n",
        "  \n",
        "  trainLeft = []\n",
        "  trainRight = []\n",
        "  Y = []\n",
        "  for eachSpeakerStartIndex in range(0,numTotalUtterances,10):\n",
        "    ConsideredSpeakerIndices = list(range(eachSpeakerStartIndex,eachSpeakerStartIndex+10))\n",
        "    \n",
        "    positivePairs = positiveSampling(ConsideredSpeakerIndices,None)\n",
        "    \n",
        "    RestSpeakerIndices = np.delete(AllIndices,ConsideredSpeakerIndices)\n",
        "    \n",
        "    negativePairs = negativeSampling(ConsideredSpeakerIndices,RestSpeakerIndices, sampleNum = 45)\n",
        "    \n",
        "    positiveLeftIndices, positiveRightIndices = [i[0] for i in positivePairs] , [i[1] for i in positivePairs] \n",
        "    negativeLeftIndices, negativeRightIndices = [i[0] for i in negativePairs] , [i[1] for i in negativePairs] \n",
        "    \n",
        "    posPlusNegXLeft = np.concatenate((positiveLeftIndices, negativeLeftIndices), axis=None)\n",
        "    posPlusNegXRight = np.concatenate((positiveRightIndices, negativeRightIndices), axis=None)\n",
        "    \n",
        "    YBatch = [1 for i in range(len(positiveLeftIndices))] + [0 for i in range(len(negativeLeftIndices))] \n",
        "    YBatch = np.array(YBatch)    \n",
        "    Y.append(YBatch)\n",
        "    leftNetworkExamples  =  AllStftArray[posPlusNegXLeft,:,:] \n",
        "    rightNetworkExamples =  AllStftArray[posPlusNegXRight,:,:] \n",
        "    trainLeft.append(leftNetworkExamples)\n",
        "    trainRight.append(rightNetworkExamples)\n",
        "    \n",
        "  return trainLeft,trainRight,Y\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPDg0Y4PVwHX",
        "colab_type": "text"
      },
      "source": [
        "# Setting up training and Details\n",
        "\n",
        "1. Generate latent vectors and take a dot product of the latent vectors\n",
        "2. sigmoid on the dot product to get 0 to 1\n",
        "3. Loss function is cross entropy \n",
        "4. Threshold 0.5 is set if prob > 0.5 then 1 is predicted\n",
        "5. Have used an GRU cell with 256 neuron output and a fully connected layer of 10 Units with tanh activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgFCqlhFz8d_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tf.reset_default_graph()\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Network Parameters\n",
        "RNNStructure = [256] ### 256  neuron layer\n",
        "FullyConnectedStructure = [10] ### One with 10 output with sigmoid activation.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg7jXOpv0rly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (numExamples,xDim) = XSpectrogramMag.shape\n",
        "# (numExamples,yDim) = YSpectrogramMag.shape\n",
        "xDim = 513\n",
        "yDim = 10\n",
        "\n",
        "XLeft = tf.placeholder(\"float\", [None,None, xDim])\n",
        "XRight = tf.placeholder(\"float\", [None,None, xDim])\n",
        "Y = tf.placeholder(\"float\", [None])\n",
        "\n",
        "# SeqLen = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "timeSteps = tf.placeholder(tf.int32)\n",
        "RNNDropout_keepProb = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ2COcFnlhTK",
        "colab_type": "text"
      },
      "source": [
        "#### defining the RNN Layer strucuure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8kVmfX61lVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##function to stack LSTMCells\n",
        "\n",
        "def stackLSTMCells(RNNStructure,reuse):\n",
        "  \n",
        "  initialiser = tf.keras.initializers.he_normal(seed=None)\n",
        "  LSTMStack = []\n",
        "  \n",
        "  for numUnits in RNNStructure: \n",
        "\n",
        "    LSTMStack.append(tf.nn.rnn_cell.GRUCell(num_units = numUnits,\n",
        "#                                              kernel_initializer = initialiser,\n",
        "                                            reuse = reuse,\n",
        "                                           name = 'GRUCell'+str(numUnits)))\n",
        "  \n",
        "  return tf.nn.rnn_cell.MultiRNNCell(LSTMStack)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pm4G-CHlaL1",
        "colab_type": "text"
      },
      "source": [
        "#### get networkoutput\n",
        "\n",
        "\n",
        "1.   Using signmoid activation fully connected layer to make the values within 0 and 1\n",
        "2.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id1CzdLgPolf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###get network output\n",
        "def getNetworkOutput(xInp,StackedCell,FullyConnectedStructure,timeSteps,reuse):\n",
        "  \n",
        "#     xInp = tf.reshape(xInp, shape=[-1, maxSeqLen , xDim])\n",
        "    \n",
        "    ### All RNN Outputs\n",
        "    StackedCell = stackLSTMCells(RNNStructure,reuse)\n",
        "    \n",
        "    outputsAtEachTimestamp ,FinalStates = tf.nn.dynamic_rnn(StackedCell,xInp,dtype = tf.float32,swap_memory = True)\n",
        "    \n",
        "    totalLayers = FullyConnectedStructure\n",
        "    \n",
        "    \n",
        "    lastLayerPosition = len(totalLayers)-1\n",
        "    outputlist = []\n",
        "  \n",
        "  \n",
        "  \n",
        "    output = tf.layers.dense(inputs = outputsAtEachTimestamp, \n",
        "                             units = 10, \n",
        "                             kernel_initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
        "                             activation = tf.nn.tanh,\n",
        "                             bias_initializer = tf.zeros_initializer(),\n",
        "                            reuse=reuse ,name = 'denseOutput1')\n",
        "    \n",
        "#     output = tf.layers.dense(inputs = output, \n",
        "#                              units = 10, \n",
        "#                              kernel_initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
        "#                              activation = tf.nn.tanh,\n",
        "#                              bias_initializer = tf.zeros_initializer(),\n",
        "#                             reuse=reuse,name = 'denseOutput')\n",
        "    \n",
        "#     for layerPosition,numUnits in enumerate(totalLayers):\n",
        "# #       \n",
        "# #       tf.print(layerPosition)\n",
        "#       if layerPosition == 0:\n",
        "      \n",
        "#         output = tf.layers.dense(outputsAtEachTimestamp, numUnits, activation=tf.nn.relu,reuse = reuse,name = \"denseLayer\"+str(layerPosition))\n",
        "    \n",
        "        \n",
        "#       elif layerPosition <= lastLayerPosition-1:\n",
        "      \n",
        "#          output = tf.layers.dense(output, numUnits, activation=tf.nn.relu,reuse = reuse,name = \"denseLayer\"+str(layerPosition))\n",
        "        \n",
        "      \n",
        "#       else:\n",
        "#         ###change activation if needed\n",
        "#         output = tf.layers.dense(output, numUnits, activation=tf.nn.tanh,reuse = reuse,name = \"denseLayer\"+str(layerPosition))\n",
        "        \n",
        "      \n",
        "    reshapedOutput = tf.reshape(output,shape = [-1,timeSteps*10])\n",
        "    return reshapedOutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EucGpqUBVlOo",
        "colab_type": "text"
      },
      "source": [
        "### Chaining all the functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rduSY_uk1Lp",
        "colab_type": "code",
        "outputId": "5989e90c-0c2c-4afa-f21d-a04f5fefb878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "## required training\n",
        "\n",
        "  \n",
        "##left network\n",
        "LastOutputLeft = getNetworkOutput(XLeft,None,FullyConnectedStructure,timeSteps,reuse = False) ##using fully connected\n",
        "\n",
        "#   scope.reuse_variables()\n",
        "\n",
        "##right network\n",
        "LastOutputRight = getNetworkOutput(XRight,None,FullyConnectedStructure,timeSteps,reuse = True) ##using fully connected\n",
        "\n",
        "\n",
        "  \n",
        "dotProduct = tf.reduce_sum(tf.multiply(LastOutputLeft,LastOutputRight),axis = 1 ,name = 'dotproduct')\n",
        "\n",
        "yPred = tf.nn.sigmoid(dotProduct)\n",
        "\n",
        "binarisedOutput = tf.cast(tf.math.greater(yPred,0.5), tf.int16)\n",
        "\n",
        "\n",
        "accuracy = tf.metrics.accuracy(labels = Y,predictions = binarisedOutput)\n",
        "\n",
        "lossCalcu = tf.nn.sigmoid_cross_entropy_with_logits(labels = Y, logits = dotProduct)\n",
        "lossCalcu  = tf.reduce_sum(lossCalcu)\n",
        "\n",
        "gradOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train = gradOptimizer.minimize(lossCalcu)\n",
        "# accuracy = RSquared(LastOutput,Y)\n",
        "\n",
        "initialise = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-008a707f9431>:12: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-9-008a707f9431>:14: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-10-ff4a33b075cd>:8: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-10-ff4a33b075cd>:23: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f74VxsCGV3Kn",
        "colab_type": "text"
      },
      "source": [
        "#### Running the training procedure for targeting same (1) and not same (0) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHpGoFdnaUjh",
        "colab_type": "code",
        "outputId": "d500a6bd-cf92-4760-e645-a21be0f8d94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(initialise)\n",
        "# train_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
        "\n",
        "\n",
        "\n",
        "trainStfts = getSTFTs(trainUtterances)\n",
        "trainXLeft,trainXRight,yTrain = genAllSpeaker(50,trainStfts)\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "  loss = []\n",
        "  for xbatchLeft,xbatchRight,yBatch in zip(trainXLeft,trainXRight,yTrain):\n",
        "\n",
        "    timeStepsInp = xbatchLeft.shape[1]\n",
        "    \n",
        "    sess.run(train,feed_dict ={XLeft: xbatchLeft,\n",
        "                               XRight: xbatchRight,Y:yBatch,\n",
        "                               timeSteps:timeStepsInp })\n",
        "\n",
        "    loss += sess.run([lossCalcu], feed_dict ={XLeft: xbatchLeft,\n",
        "                                              XRight: xbatchRight,Y:yBatch,\n",
        "                                              timeSteps:timeStepsInp })  \n",
        "    \n",
        "#     accu = sess.run(accuracy, feed_dict ={XLeft: xbatchLeft,\n",
        "#                                               XRight: xbatchRight,Y:yBatch,\n",
        "#                                               timeSteps:timeStepsInp })\n",
        "   \n",
        "  print(\"Step \" + str(epoch) + \", Loss= \" + str(sum(loss)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss= 11666.8208694458\n",
            "Step 1, Loss= 3732.192523956299\n",
            "Step 2, Loss= 2518.712100982666\n",
            "Step 3, Loss= 2150.1600608825684\n",
            "Step 4, Loss= 1897.5947713851929\n",
            "Step 5, Loss= 1718.8840990066528\n",
            "Step 6, Loss= 1804.9715881347656\n",
            "Step 7, Loss= 1595.3043308258057\n",
            "Step 8, Loss= 1299.6066632270813\n",
            "Step 9, Loss= 1077.1792073249817\n",
            "Step 10, Loss= 886.3827857971191\n",
            "Step 11, Loss= 771.3760724067688\n",
            "Step 12, Loss= 675.0853085517883\n",
            "Step 13, Loss= 588.5127789974213\n",
            "Step 14, Loss= 596.3003215789795\n",
            "Step 15, Loss= 430.77843260765076\n",
            "Step 16, Loss= 429.9031431674957\n",
            "Step 17, Loss= 374.20227658748627\n",
            "Step 18, Loss= 276.2902705669403\n",
            "Step 19, Loss= 255.90630501508713\n",
            "Step 20, Loss= 282.39414632320404\n",
            "Step 21, Loss= 287.11185759305954\n",
            "Step 22, Loss= 224.50875449180603\n",
            "Step 23, Loss= 123.96298438310623\n",
            "Step 24, Loss= 84.43239688128233\n",
            "Step 25, Loss= 56.74008375406265\n",
            "Step 26, Loss= 37.98302336037159\n",
            "Step 27, Loss= 30.53698781877756\n",
            "Step 28, Loss= 25.19704645872116\n",
            "Step 29, Loss= 21.728830941021442\n",
            "Step 30, Loss= 19.425675380975008\n",
            "Step 31, Loss= 17.580969132483006\n",
            "Step 32, Loss= 16.00543314218521\n",
            "Step 33, Loss= 14.628147177398205\n",
            "Step 34, Loss= 13.410082172602415\n",
            "Step 35, Loss= 12.325582142919302\n",
            "Step 36, Loss= 11.355895087122917\n",
            "Step 37, Loss= 10.486250314861536\n",
            "Step 38, Loss= 9.704391319304705\n",
            "Step 39, Loss= 8.999838933348656\n",
            "Step 40, Loss= 8.363510143011808\n",
            "Step 41, Loss= 7.787499915808439\n",
            "Step 42, Loss= 7.264912988990545\n",
            "Step 43, Loss= 6.789731066673994\n",
            "Step 44, Loss= 6.35669607296586\n",
            "Step 45, Loss= 5.961208689957857\n",
            "Step 46, Loss= 5.599236946552992\n",
            "Step 47, Loss= 5.267243914306164\n",
            "Step 48, Loss= 4.962116168811917\n",
            "Step 49, Loss= 4.681113634258509\n",
            "Step 50, Loss= 4.421817246824503\n",
            "Step 51, Loss= 4.182095987722278\n",
            "Step 52, Loss= 3.960056906566024\n",
            "Step 53, Loss= 3.754029421135783\n",
            "Step 54, Loss= 3.56252596154809\n",
            "Step 55, Loss= 3.3842268642038107\n",
            "Step 56, Loss= 3.217952886596322\n",
            "Step 57, Loss= 3.06265508569777\n",
            "Step 58, Loss= 2.9173925686627626\n",
            "Step 59, Loss= 2.7813241239637136\n",
            "Step 60, Loss= 2.653693376109004\n",
            "Step 61, Loss= 2.533820081502199\n",
            "Step 62, Loss= 2.4210920613259077\n",
            "Step 63, Loss= 2.3149545025080442\n",
            "Step 64, Loss= 2.2149072997272015\n",
            "Step 65, Loss= 2.1204958893358707\n",
            "Step 66, Loss= 2.031307827681303\n",
            "Step 67, Loss= 1.946968830190599\n",
            "Step 68, Loss= 1.8671364476904273\n",
            "Step 69, Loss= 1.7914984626695514\n",
            "Step 70, Loss= 1.7197703439742327\n",
            "Step 71, Loss= 1.6516901860013604\n",
            "Step 72, Loss= 1.5870187478139997\n",
            "Step 73, Loss= 1.5255358079448342\n",
            "Step 74, Loss= 1.4670392274856567\n",
            "Step 75, Loss= 1.4113426161929965\n",
            "Step 76, Loss= 1.358274007216096\n",
            "Step 77, Loss= 1.3076747236773372\n",
            "Step 78, Loss= 1.2593978336080909\n",
            "Step 79, Loss= 1.213307618163526\n",
            "Step 80, Loss= 1.1692778244614601\n",
            "Step 81, Loss= 1.1271921154111624\n",
            "Step 82, Loss= 1.0869416864588857\n",
            "Step 83, Loss= 1.0484251966699958\n",
            "Step 84, Loss= 1.0115489289164543\n",
            "Step 85, Loss= 0.9762250948697329\n",
            "Step 86, Loss= 0.9423719150945544\n",
            "Step 87, Loss= 0.9099129363894463\n",
            "Step 88, Loss= 0.8787766369059682\n",
            "Step 89, Loss= 0.8488962100818753\n",
            "Step 90, Loss= 0.8202091339044273\n",
            "Step 91, Loss= 0.7926565171219409\n",
            "Step 92, Loss= 0.7661828370764852\n",
            "Step 93, Loss= 0.7407365501858294\n",
            "Step 94, Loss= 0.7162688188254833\n",
            "Step 95, Loss= 0.6927338619716465\n",
            "Step 96, Loss= 0.6700883326120675\n",
            "Step 97, Loss= 0.6482914434745908\n",
            "Step 98, Loss= 0.6273049334995449\n",
            "Step 99, Loss= 0.6070923297666013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3yAucwijDhB",
        "colab_type": "text"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Segd9qTjrD9",
        "colab_type": "text"
      },
      "source": [
        "Here I am randomly sampling from the test file random pairs same as training hence for each speaker I ll have 45 positive pairs and 45 negative pairs.\n",
        "\n",
        "And there are 20 speakers in total. Hence the shape of XLeft is (20,90,Len,513)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI1GnXOuSrhe",
        "colab_type": "code",
        "outputId": "561f79df-0085-4312-ed4b-46c7777aa09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "with open(dirpath+'hw4_tes.pkl', 'rb') as f:\n",
        "  testUtterances = p.load(f)\n",
        "  \n",
        "\n",
        "testStfts = getSTFTs(testUtterances)\n",
        "\n",
        "testXLeft,testXRight,yTest = genAllSpeaker(10,testStfts)\n",
        "\n",
        "testXLeft,testXRight,yTest = np.array(testXLeft).reshape((-1,45,513)), np.array(testXRight).reshape((-1,45,513)), np.array(yTest).reshape(-1)\n",
        "\n",
        "yPrediction = sess.run(binarisedOutput, feed_dict ={XLeft: testXLeft,\n",
        "                                      XRight: testXRight,Y:yTest,\n",
        "                                      timeSteps:testXLeft.shape[1]})\n",
        "\n",
        "print(\"The accuracy on the test set is :\", 100* sum(yPrediction == yTest)/yTest.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy on the test set is : [69.61111111]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZfJDdOBbSIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}