{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_3_Problem1_1.5 and 1.6a.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ArgyvO-G0G2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import random\n",
        "import matplotlib.cm as cm\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klOEFzEA04o-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question 1.5\n",
        "\n",
        "#### Pretraining the network to obtain weights"
      ]
    },
    {
      "metadata": {
        "id": "ZW5zhy_59iLN",
        "colab_type": "code",
        "outputId": "8f3e0a74-8ef3-4b2d-b774-54c71815aaa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Heere we define network parametes and build the computational graph\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "##network params\n",
        "learning_rate = tf.constant(0.0003)\n",
        "numEpochs = 400\n",
        "batchSize = 50\n",
        "displayStep = 5\n",
        "nodesInEachHiddenLayer = [1024,1024,1024,1024,1024]  #list of nodes  excpet x and y\n",
        "\n",
        "numExamples,xDim = mnist.train.images.shape\n",
        "numExamples,yDim = mnist.train.labels.shape\n",
        "\n",
        "\n",
        "totalNodes = nodesInEachHiddenLayer\n",
        "X = tf.placeholder(tf.float32,[None,xDim],name = \"X\")\n",
        "Y  =  tf.placeholder(tf.float32,[None,yDim], name = \"Y\")\n",
        "\n",
        "\n",
        "\n",
        "## collecting weights in a dictionary\n",
        "\n",
        "\n",
        "\n",
        "def defineWeightsAndBias(nodesInEachHiddenLayer,xDim, yDim):\n",
        "  \n",
        "  ## he inisitialisation\n",
        "  initialiser = tf.contrib.layers.variance_scaling_initializer()\n",
        "  \n",
        "  weights = [tf.Variable(initialiser([j,k],dtype=tf.float32)) \\\n",
        "             for (j,k) in zip([xDim]+nodesInEachHiddenLayer,nodesInEachHiddenLayer+[yDim])]\n",
        "  \n",
        "  \n",
        "  biases = [tf.Variable(initialiser([j],dtype=tf.float32))\n",
        "           for j in nodesInEachHiddenLayer+[yDim]]\n",
        "\n",
        "#   weights = {'w'+str(i+1): tf.Variable(tf.random_normal([j,k],dtype=tf.float32)) \\\n",
        "#              for (i,(j,k)) in enumerate(zip([xDim]+nodesInEachHiddenLayer,nodesInEachHiddenLayer+[yDim]))}\n",
        "\n",
        "#   biases = {'b'+str(i+1): tf.Variable(tf.random_normal([j],dtype=tf.float32))\n",
        "#            for i,j in enumerate(nodesInEachHiddenLayer+[yDim])}\n",
        "\n",
        "  return weights, biases\n",
        "\n",
        "\n",
        "\n",
        "def getNetworkOutput(xInp,weights,biases):\n",
        "  \n",
        "    totalLayers = nodesInEachHiddenLayer+[yDim]\n",
        "    layerOutputList = [0 for i in  range(len(totalLayers))]\n",
        "    \n",
        "    lastLayerPosition = len(totalLayers)-1\n",
        "    \n",
        "    for layerPosition,(weight,bias) in enumerate(zip(weights,biases)):\n",
        "\n",
        "      if layerPosition == 0:\n",
        "      \n",
        "        layerOutputList[layerPosition] = tf.nn.relu(tf.add(tf.matmul(xInp, weight), bias))\n",
        "         \n",
        "\n",
        "\n",
        "      elif layerPosition <= lastLayerPosition-1:\n",
        "      \n",
        "        layerOutputList[layerPosition] = tf.nn.relu(tf.add(tf.matmul(layerOutputList[layerPosition-1], weight), bias))\n",
        "        \n",
        "      \n",
        "      else:\n",
        "        \n",
        "        layerOutputList[layerPosition] = tf.add(tf.matmul(layerOutputList[layerPosition-1], weight), bias)\n",
        "#         layerOut = tf.nn.relu(layerOut,name='activation_relu')\n",
        "      \n",
        "    \n",
        "    return layerOutputList[-1],layerOutputList\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q4w05KY-Vb_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##call by functions\n",
        "\n",
        "weights,biases = defineWeightsAndBias(nodesInEachHiddenLayer,xDim, yDim)\n",
        "layer_Output, AllLayerOutputs = getNetworkOutput(X,weights,biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_eV8WcuRZez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##loss calculations\n",
        "\n",
        "\n",
        "lossCalcu  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_Output, labels=Y))\n",
        "\n",
        "gradOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train = gradOptimizer.minimize(lossCalcu)\n",
        "\n",
        "## required Layers tensors\n",
        "predictions = tf.nn.softmax(AllLayerOutputs[-1])\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(layer_Output, 1), tf.argmax(Y, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "initialise = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8AV9WAlRmIR",
        "colab_type": "code",
        "outputId": "b59b8542-690f-4e4c-a062-bfbc471588b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "currSess = tf.InteractiveSession()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train = mnist.train.images\n",
        "\n",
        "y_train = mnist.train.labels\n",
        "\n",
        "##training \n",
        "currSess.run(initialise)\n",
        "\n",
        "x_test = mnist.test.images\n",
        "y_test = mnist.test.labels\n",
        "\n",
        "for epoch in range(200):\n",
        "  for iteration in range(mnist.train.num_examples // batchSize):\n",
        "    xBatch, yBatch = mnist.train.next_batch(batchSize)  \n",
        "\n",
        "\n",
        "    currSess.run(train,feed_dict ={X:xBatch,Y:yBatch})\n",
        "\n",
        "\n",
        "  loss, acc = currSess.run([lossCalcu, accuracy], feed_dict={X: x_train, Y: y_train})  \n",
        "\n",
        "\n",
        "  print(\"Step \" + str(epoch) + \", Loss= \" + str(loss) + \", Training Accuracy= \" + str(acc))\n",
        "\n",
        "\n",
        "  testAccuracy = currSess.run(accuracy, feed_dict={X: x_test,\n",
        "                                Y:y_test })\n",
        "  print(\"Testing Accuracy:\",testAccuracy)\n",
        "###printing the images for q3\n",
        "\n",
        "  if testAccuracy >= 0.98:\n",
        "    break\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss= 0.08887421, Training Accuracy= 0.9734727\n",
            "Testing Accuracy: 0.9642\n",
            "Step 1, Loss= 0.05022041, Training Accuracy= 0.9850182\n",
            "Testing Accuracy: 0.9697\n",
            "Step 2, Loss= 0.042661045, Training Accuracy= 0.98752725\n",
            "Testing Accuracy: 0.9715\n",
            "Step 3, Loss= 0.02873116, Training Accuracy= 0.99163634\n",
            "Testing Accuracy: 0.9743\n",
            "Step 4, Loss= 0.03629114, Training Accuracy= 0.9899455\n",
            "Testing Accuracy: 0.9742\n",
            "Step 5, Loss= 0.0261305, Training Accuracy= 0.99236363\n",
            "Testing Accuracy: 0.9758\n",
            "Step 6, Loss= 0.016531412, Training Accuracy= 0.9947091\n",
            "Testing Accuracy: 0.9793\n",
            "Step 7, Loss= 0.012913459, Training Accuracy= 0.9961454\n",
            "Testing Accuracy: 0.981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "75EUG-Wji41V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### get SVD approximated weights from original weight matrices"
      ]
    },
    {
      "metadata": {
        "id": "7wSx3d4bYGuB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def SVDWeights(weightsList,topN = None):\n",
        "  approxWeightsList = []\n",
        "  lastPosition = len(weightsList)-1\n",
        "  for position,weight in enumerate(weightsList):\n",
        "\n",
        "    if position != lastPosition:\n",
        "      \n",
        "      \n",
        "      if topN is not None:\n",
        "        s, u, v = tf.linalg.svd(weight,full_matrices=True)\n",
        "        approxWeightsList.append(tf.matmul(u[:,:topN], tf.matmul(tf.linalg.diag(s[:topN]), v[:,:topN], adjoint_b=True)))\n",
        "        \n",
        "      elif topN is None:\n",
        "        s, u, v = tf.linalg.svd(weight,full_matrices=False)\n",
        "        approxWeightsList.append(tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True)))\n",
        "    \n",
        "    elif position == lastPosition:\n",
        "       approxWeightsList.append(weightsList[-1])\n",
        "    \n",
        "  return approxWeightsList\n",
        "\n",
        "# layer_Output, AllLayerOutputs = getNetworkOutput(X,weights,biases)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MwnoPS0yhfz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Feed forward with different D's "
      ]
    },
    {
      "metadata": {
        "id": "Knc7kU63mFYp",
        "colab_type": "code",
        "outputId": "c460f53b-2f0c-4eb3-a55d-a12378316363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for D in [10, 20, 50, 100, 200,None]:\n",
        "  approxWeightsList = SVDWeights(weights,D)\n",
        "  layer_Output, AllLayerOutputs = getNetworkOutput(X,approxWeightsList,biases)\n",
        "  predictions = tf.nn.softmax(AllLayerOutputs[-1])\n",
        "\n",
        "  correct_pred = tf.equal(tf.argmax(layer_Output, 1), tf.argmax(Y, 1))\n",
        "\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "  testAccuracy = currSess.run(accuracy, feed_dict={X: x_test,\n",
        "                                Y:y_test })\n",
        "  print(\" D is : \", D ,\" and Testing Accuracy is : \",testAccuracy)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " D is :  10  and Testing Accuracy is :  0.6915\n",
            " D is :  20  and Testing Accuracy is :  0.9424\n",
            " D is :  50  and Testing Accuracy is :  0.9731\n",
            " D is :  100  and Testing Accuracy is :  0.9778\n",
            " D is :  200  and Testing Accuracy is :  0.9784\n",
            " D is :  None  and Testing Accuracy is :  0.9802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qAF7GIpdhLC2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Storing all the variables that were previously initialised (weight matrices specifically so that they are not re initialised)"
      ]
    },
    {
      "metadata": {
        "id": "p-QqimrQhE4r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "varsAlreadyInititalised = set(tf.all_variables())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inJhoC2CDXOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Freezing weights in numpy and converting them non trainable"
      ]
    },
    {
      "metadata": {
        "id": "j5l1aaiB-tSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = [weight.eval() for weight in weights]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ynZiXflK56AZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.6 a\n",
        "\n",
        "#### Decomposing weights into U and Vhat with D = 20 and storing them in a list "
      ]
    },
    {
      "metadata": {
        "id": "sw1Q9feWfsoU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def decomposeWeights(weightsList,topN = None):\n",
        "  \n",
        "  decomposedWeightsList = []\n",
        "  \n",
        "  lastPosition = len(weightsList)-1\n",
        "  for position,weight in enumerate(weightsList):\n",
        "\n",
        "    if position != lastPosition:\n",
        "      \n",
        "      \n",
        "      if topN is not None:\n",
        "        s, u, v = tf.linalg.svd(weight,full_matrices=True)\n",
        "        \n",
        "        vHat = tf.Variable(tf.matmul(tf.linalg.diag(s[:topN]), v[:,:topN], adjoint_b=True))\n",
        "        \n",
        "        u = tf.Variable(u[:,:topN])\n",
        "        \n",
        "        ###u and vhat are put into a tuple\n",
        "        decomposedWeightsList.append((u, vHat))\n",
        "        \n",
        "    \n",
        "    elif position == lastPosition:\n",
        "       decomposedWeightsList.append(weightsList[-1])\n",
        "    \n",
        "  return decomposedWeightsList\n",
        "\n",
        "decomposedWeightsList = decomposeWeights(weights,topN = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGTCrgL8ghbE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### network out put with SVD decomposition takes in decompedWeightsList as one of the argument"
      ]
    },
    {
      "metadata": {
        "id": "iJCUHS_75sYQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def getNetworkWithSVDOutput(xInp,decomposedWeightsList,biases):\n",
        "  \n",
        "    totalLayers = nodesInEachHiddenLayer+[yDim]\n",
        "    \n",
        "    \n",
        "    lastLayerPosition = len(totalLayers)-1\n",
        "    \n",
        "    for layerPosition,(weight,bias) in enumerate(zip(decomposedWeightsList,biases)):\n",
        "\n",
        "      if layerPosition == 0:\n",
        "        \n",
        "        ## u * vhat:  weight [0] contains u and weight[1] contains vhat\n",
        "        approxWeight = tf.matmul(weight[0], weight[1])\n",
        "        \n",
        "        output = tf.nn.relu(tf.add(tf.matmul(xInp, approxWeight), bias))\n",
        "        \n",
        "\n",
        "\n",
        "      elif layerPosition <= lastLayerPosition-1:\n",
        "        \n",
        "        approxWeight = tf.matmul(weight[0], weight[1])\n",
        "        output = tf.nn.relu(tf.add(tf.matmul(output, approxWeight), bias))\n",
        "        \n",
        "      \n",
        "      else:\n",
        "        \n",
        "        output= tf.add(tf.matmul(output, weight), bias)\n",
        "#         layerOut = tf.nn.relu(layerOut,name='activation_relu')\n",
        "      \n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNuYWg2Ag4je",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### defining the rest of the trainng and accuracy calls \n",
        "\n",
        "getNetworkWithSVDOutput(X,decomposedWeightsList,biases) is called here"
      ]
    },
    {
      "metadata": {
        "id": "op8bf3ZLZ2Qu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###output with new SVD decomposition\n",
        "\n",
        "layerOutputSVD = getNetworkWithSVDOutput(X,decomposedWeightsList,biases)\n",
        "lossCalcu  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=layerOutputSVD, labels=Y))\n",
        "\n",
        "gradOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train = gradOptimizer.minimize(lossCalcu)\n",
        "\n",
        "## required Layers tensors\n",
        "predictions = tf.nn.softmax(layerOutputSVD)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(layerOutputSVD, 1), tf.argmax(Y, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "###initialising only those variable that were not initialised previously so that the weight matrices are not reinitialised\n",
        "currSess.run(tf.variables_initializer(set(tf.all_variables()) - varsAlreadyInititalised))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wn_UXvmfga5z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training procedure as usual"
      ]
    },
    {
      "metadata": {
        "id": "5oQ-RI_gYQ-O",
        "colab_type": "code",
        "outputId": "62fbacb8-b69c-4755-a0c7-5f2316807673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "##training \n",
        "x_train = mnist.train.images\n",
        "\n",
        "y_train = mnist.train.labels\n",
        "\n",
        "\n",
        "\n",
        "x_test = mnist.test.images\n",
        "y_test = mnist.test.labels\n",
        "\n",
        "for epoch in range(200):\n",
        "  for iteration in range(mnist.train.num_examples // batchSize):\n",
        "    xBatch, yBatch = mnist.train.next_batch(batchSize)  \n",
        "\n",
        "\n",
        "    currSess.run(train,feed_dict ={X:xBatch,Y:yBatch})\n",
        "\n",
        "\n",
        "  loss, acc = currSess.run([lossCalcu, accuracy], feed_dict={X: x_train, Y: y_train})  \n",
        "\n",
        "\n",
        "  print(\"Step \" + str(epoch) + \", Loss= \" + str(loss) + \", Training Accuracy= \" + str(acc))\n",
        "\n",
        "\n",
        "  testAccuracy = currSess.run(accuracy, feed_dict={X: x_test,\n",
        "                                Y:y_test })\n",
        "  print(\"Testing Accuracy:\",testAccuracy)\n",
        "###printing the images for q3\n",
        "\n",
        "  if testAccuracy >= 0.97:\n",
        "    break\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss= 0.051006038, Training Accuracy= 0.98414546\n",
            "Testing Accuracy: 0.9747\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}